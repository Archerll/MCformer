# MCformer
Paper:[MCformer: Multivariate Time Series Forecasting With Mixed-Channels Transformer](https://arxiv.org/abs/2403.09223)

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)
![nVIDIA](https://img.shields.io/badge/cuda-000000.svg?style=for-the-badge&logo=nVIDIA&logoColor=green)

## Introduction


## Overall Architecture
<img width="841" alt="MCFormer_Arch" src="https://github.com/user-attachments/assets/830cebf5-b36f-469d-ba35-149fb21f1027" />

## Usage 

1. Install Pytorch and necessary dependencies.

```
pip install -r requirements.txt
```

## Main Result of Multivariate Forecasting

![图片](https://github.com/user-attachments/assets/22c66962-aa3e-43f8-9c6c-0fa43872a0e0)

## Citation

If you find this repo helpful, please cite our paper. 

```
@ARTICLE{10533212,
  author={Han, Wenyong and Zhu, Tao and Chen, Liming and Ning, Huansheng and Luo, Yang and Wan, Yaping},
  journal={IEEE Internet of Things Journal}, 
  title={MCformer: Multivariate Time Series Forecasting With Mixed-Channels Transformer}, 
  year={2024},
  volume={11},
  number={17},
  pages={28320-28329},
  keywords={Time series analysis;Forecasting;Predictive models;Data models;Internet of Things;Correlation;Transformers;Long time series;multivariate time series;self-attention;time series forecasting},
  doi={10.1109/JIOT.2024.3401697}}
```

## Acknowledgement

We appreciate the following GitHub repos a lot for their valuable code and efforts.
- Reformer (https://github.com/lucidrains/reformer-pytorch)
- Informer (https://github.com/zhouhaoyi/Informer2020)
- Autoformer (https://github.com/thuml/Autoformer)
- Stationary (https://github.com/thuml/Nonstationary_Transformers)
- Time-Series-Library (https://github.com/thuml/Time-Series-Library)
- PatchTST (https://github.com/yuqinie98/PatchTST)


